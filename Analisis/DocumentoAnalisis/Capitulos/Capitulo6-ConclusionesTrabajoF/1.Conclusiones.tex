\section{Conclusiones}

La cantidad de páginas electrónicas, para consultar noticias ha incrementado con el paso de los años, su información al igual que un diario tradicional se encuentra dividida en secciones para facilitar 
la consulta, sin embargo, la clasificación suele variar en cada portal, incluso teniendo el mismo contenido. Por esta razón, buscar artículos de interés se ha hecho una tarea complicada y laboriosa. Para abordar una solución con base en este problema, el presente trabajo ha desarrollado
una aplicación web, el cual permite recopilar noticias de diferentes fuentes y mediante un algoritmo son clasificadas automáticamente en 5 secciones diferentes.\\


Como primer punto abordado en el desarrollo de este trabajo, se debe mencionar que uno de los objetivos particulares de este TT, es afinar el clasificador del trabajo terminal 2017-A042, sin embargo, debido a los diferentes enfoques de clasificación se decidió generar un nuevo modelo y corpus.\\ 

Se recolecto un corpus de 3,500 noticias, con el fin de tener información suficiente para entrenar y probar 4 algoritmos de clasificación de la biblioteca \textbf{scikit-learn} los cuales son: \textbf{Naive Bayes}, \textbf{Regresión logística}, \textbf{Random Forest} y \textbf{Maquina de soporte vectorial}. Además para medir la eficiencia de los algoritmos se ha hecho uso de la técnica validación cruzada, el cual consiste en dividir un corpus en conjunto de entrenamiento y prueba, calcular la exactitud de cada prueba y obtener el promedio total. \textbf{Maquina de soporte vectorial} ha tenido el mejor resultado con una exactitud de 0.869, por esta razón el modelo clasificador se ha entrenado con este algoritmo. 

Para recolectar las noticia se ha utilizado la impelentación de la librería \textbf{scrapy}, el cual permite crear arañas que extraen los elementos de las noticias (\textbf{título}, \textbf{URL}, \textbf{Contenido}, etc) de 7 sitios web. Cabe destacar que el desarrollo de ambas herramientas ( modelo clasificador y recolector ) se ha hecho en el lenguaje \textbf{python 3}.\\

Como segundo aspecto a abarcar, la implementación de la aplicación web tiene dos partes fundamentales: la vista  y el procesamiento de los datos. Para esta última parte se ha usado \textbf{Java} como lenguaje de programación, además para conectar esta etapa con la recolección y clasificación se han usado subprocesos, los cuales son iniciados en la aplicación. En la primera etapa (recolección) se obtienen noticias de los sitios web, al concluir esta tarea la segunda etapa es iniciada ( clasificación ), en la cual se hace un procesamiento al contenido de la noticia, para pasar el contenido en lenguaje natural a un vector de características ocupado para la clasificación de las noticias, al concluir esta tarea, se obtiene el resultado y es presentado en la vista. El diseño del entorno web se ha hecho en  \textbf{HTML}, \textbf{CSS} y \textbf{Java server faces}, este muestra al usuario las noticias divididas en las 5 secciones definidas. Cabe mencionar que el usuario tiene la opción de filtrar las noticias por fecha en las siguientes categorías: hoy, ayer, dos días y tres días o mas.\\

Como conclusión se puede decir que el objetivo principal se ha alcanzado, con buenos resultados en la clasificación.



%El presente trabajo evaluó las técnicas existentes para la recolección de información de sitios %web, así como la representación de la información recolectada, la selección de características, %para finalmente realizar pruebas con los algoritmos de clasificación mencionados, con el fin de %obtener el mejor algoritmo que se adecue a nuestro objetivo, el cual es clasificar noticias.%
%
%Las consideraciones en el corpus utilizado, nos permitió obtener mejores resultados, ya que se %omitieron palabras, símbolos así como se valido la longitud de la noticia, lo cual nos podía %arrojar una clasificación errónea.

%
%1 Objetivo general
%2 Objetivos particulares
%3 Recolección de noticia
%4 Clasificación de noticia
%5 Resultados%